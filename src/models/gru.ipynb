{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "953153b5",
   "metadata": {},
   "source": [
    "## Construct line graph from toy example\n",
    "- Check python kernel and import graph construction libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49a358c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.graph import SNAPSHOTS\n",
    "import networkx as nx\n",
    "import math\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8eb56a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "WEATHER_FEATURES = ['wind', 'wind_max', 'temperature', 'rain', 'rain_duration', 'fog', 'snow', 'thunder', 'ice']\n",
    "NODE_TYPES = ['TRAIN', 'WEATHER']\n",
    "EDGE_TYPES = ['TRAIN', 'WEATHER', 'DISRUPTION']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4448be3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = SNAPSHOTS[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0166e14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_minimal_graph(graph):\n",
    "    H = nx.Graph()\n",
    "    H.graph = graph.graph.copy()\n",
    "\n",
    "    for node, attrs in graph.nodes(data=True):\n",
    "        if attrs.get(\"type\") != \"TRAIN\":\n",
    "            continue\n",
    "\n",
    "        ws_code = attrs.get(\"weather_station\")\n",
    "        ws_attrs = graph.nodes[ws_code]\n",
    "        \n",
    "        node_features = {}\n",
    "        for feat in WEATHER_FEATURES:\n",
    "            node_features[feat] = float(ws_attrs.get(feat, 0.0))\n",
    "        H.add_node(node, **node_features)\n",
    "\n",
    "    for u, v, eattrs in graph.edges(data=True):\n",
    "        if eattrs.get(\"type\") != \"WEATHER\":\n",
    "            duration = eattrs.get(\"duration\", 0)\n",
    "            H.add_edge(u, v, duration=duration)\n",
    "    \n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63dd431b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_linegraph(G):\n",
    "    LG = nx.line_graph(G)\n",
    "    LG.graph = G.graph.copy()\n",
    "    for (u,v) in LG.nodes:\n",
    "        LG.nodes[u,v]['duration'] = G.edges[u,v]['duration']\n",
    "    for node_u, node_v in LG.edges:\n",
    "        s = (set(node_u) & set(node_v)).pop()\n",
    "        for feat in WEATHER_FEATURES:\n",
    "            LG.edges[node_u, node_v][feat] = G.nodes[s][feat]\n",
    "    return LG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0af15ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph with 431 nodes and 581 edges\n"
     ]
    }
   ],
   "source": [
    "LG = make_linegraph(build_minimal_graph(G))\n",
    "print(LG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac05640",
   "metadata": {},
   "source": [
    "## GCN + RNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8ca3534",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\andre\\miniconda3\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "import random, numpy as np\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7415ac88",
   "metadata": {},
   "source": [
    "- Data preparation for GCN + RNN\n",
    "- Mean temperature as feature vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9dbb1f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('NSCH', 'WS'): 0, ('DZ', 'DZW'): 1, ('HDR', 'HDRZ'): 2, ('EEM', 'RD'): 3, ('EDN', 'MTR'): 4, ('EMN', 'EMNZ'): 5, ('BKF', 'EKZ'): 6, ('EGHM', 'LG'): 7, ('ESE', 'GBR'): 8, ('HLG', 'HLGH'): 9, ('KPN', 'ZLSH'): 10, ('CVM', 'KRD'): 11, ('HGLO', 'ODZ'): 12, ('RHN', 'VNDC'): 13, ('KMW', 'STV'): 14, ('UTM', 'UTO'): 15, ('VDM', 'ZB'): 16, ('VS', 'VSS'): 17, ('OVN', 'ZVT'): 18, ('ATN', 'VSV'): 19, ('TBG', 'VSV'): 20, ('BGN', 'RB'): 21, ('KBD', 'RB'): 22, ('DL', 'ZL'): 23, ('WH', 'ZL'): 24, ('GN', 'GNN'): 25, ('GNN', 'SWD'): 26, ('AC', 'ASHD'): 27, ('ASB', 'ASHD'): 28, ('HGZ', 'MTH'): 29, ('HGZ', 'ZB'): 30, ('HVSP', 'HOR'): 31, ('HOR', 'UTO'): 32, ('BTL', 'OT'): 33, ('BTL', 'VG'): 34, ('BLL', 'HLM'): 35, ('HLM', 'HLMS'): 36, ('DT', 'DTCP'): 37, ('DTCP', 'SDM'): 38, ('PMR', 'PMW'): 39, ('PMW', 'ZDK'): 40, ('HNP', 'WK'): 41, ('IJT', 'WK'): 42, ('BHV', 'UTO'): 43, ('UT', 'UTO'): 44, ('BMR', 'CK'): 45, ('CK', 'MMLH'): 46, ('HT', 'HTO'): 47, ('HT', 'TB'): 48, ('BSMZ', 'HVSM'): 49, ('HVS', 'HVSM'): 50, ('BKF', 'BKG'): 51, ('AKL', 'GR'): 52, ('AKL', 'LDM'): 53, ('AKM', 'HR'): 54, ('HR', 'HRY'): 55, ('ZL', 'ZLSH'): 56, ('BP', 'DWE'): 57, ('BP', 'GK'): 58, ('CO', 'DLN'): 59, ('DLN', 'NA'): 60, ('APD', 'APDO'): 61, ('APD', 'BNN'): 62, ('HT', 'VG'): 63, ('CO', 'GBG'): 64, ('ARN', 'MDB'): 65, ('MDB', 'VS'): 66, ('OST', 'WH'): 67, ('DVNK', 'LEDN'): 68, ('LEDN', 'SSH'): 69, ('BLL', 'SPTZ'): 70, ('EHV', 'EHS'): 71, ('EHV', 'HMBV'): 72, ('ASB', 'DVD'): 73, ('RAI', 'DVD'): 74, ('BET', 'BTL'): 75, ('BET', 'EHS'): 76, ('BRN', 'HVS'): 77, ('OT', 'TB'): 78, ('BNK', 'DB'): 79, ('DB', 'MRN'): 80, ('GDM', 'TPSW'): 81, ('GDM', 'ZBM'): 82, ('GD', 'GDG'): 83, ('GDG', 'WD'): 84, ('DMN', 'WP'): 85, ('NDB', 'WP'): 86, ('KPNZ', 'ZL'): 87, ('HB', 'NH'): 88, ('NH', 'SN'): 89, ('AH', 'AHZ'): 90, ('AH', 'OTB'): 91, ('BRD', 'ZLW'): 92, ('BDPB', 'ZLW'): 93, ('KMA', 'WM'): 94, ('WM', 'ZZS'): 95, ('HDB', 'MRB'): 96, ('MRB', 'VHP'): 97, ('ARN', 'GS'): 98, ('HBZM', 'GND'): 99, ('HBZM', 'SDT'): 100, ('BF', 'WSM'): 101, ('SWD', 'WSM'): 102, ('AMRN', 'HWD'): 103, ('HWD', 'OBD'): 104, ('DV', 'OST'): 105, ('ZLW', 'ZVB'): 106, ('CVM', 'EGH'): 107, ('EGH', 'LG'): 108, ('BNC', 'BNZ'): 109, ('BNZ', 'LTN'): 110, ('SGL', 'MES'): 111, ('MTN', 'MES'): 112, ('CPS', 'NWK'): 113, ('GD', 'NWK'): 114, ('BRN', 'SD'): 115, ('ST', 'SD'): 116, ('WZ', 'ZL'): 117, ('ASS', 'HWZB'): 118, ('ASS', 'ZD'): 119, ('KBD', 'KRG'): 120, ('BR', 'HRT'): 121, ('BR', 'VRY'): 122, ('HRY', 'WV'): 123, ('SWK', 'WV'): 124, ('HTO', 'RS'): 125, ('OW', 'RS'): 126, ('ED', 'WF'): 127, ('OTB', 'WF'): 128, ('HGV', 'MP'): 129, ('MP', 'SWK'): 130, ('AML', 'WDN'): 131, ('RSN', 'WDN'): 132, ('HRL', 'LG'): 133, ('ED', 'KLP'): 134, ('NMD', 'WC'): 135, ('RVS', 'WC'): 136, ('AH', 'AHP'): 137, ('BMN', 'ZP'): 138, ('LC', 'ZP'): 139, ('EDC', 'ED'): 140, ('DWE', 'FWD'): 141, ('FWD', 'HDG'): 142, ('BHDV', 'GR'): 143, ('BHDV', 'GND'): 144, ('BNN', 'HVL'): 145, ('BDG', 'WD'): 146, ('MRN', 'VNDW'): 147, ('VNDC', 'VNDW'): 148, ('ESK', 'HGL'): 149, ('HGL', 'HGLG'): 150, ('HN', 'OBD'): 151, ('CL', 'GDM'): 152, ('UT', 'UTLR'): 153, ('UT', 'UTVR'): 154, ('GVC', 'LAA'): 155, ('GV', 'LAA'): 156, ('DV', 'TWL'): 157, ('MP', 'ZL'): 158, ('HK', 'UTG'): 159, ('KMA', 'UTG'): 160, ('HN', 'HNK'): 161, ('HN', 'PMO'): 162, ('ASDL', 'ASS'): 163, ('NMD', 'NMGO'): 164, ('BN', 'HGL'): 165, ('ZD', 'ZDK'): 166, ('KTR', 'OP'): 167, ('KTR', 'TL'): 168, ('CAS', 'UTG'): 169, ('VD', 'ZP'): 170, ('FN', 'HLG'): 171, ('DA', 'VHP'): 172, ('BNK', 'UTVR'): 173, ('PMR', 'PMO'): 174, ('EHV', 'GP'): 175, ('GP', 'HZE'): 176, ('GN', 'GERP'): 177, ('GN', 'ZH'): 178, ('AMF', 'DLD'): 179, ('BHV', 'DLD'): 180, ('AHZ', 'EST'): 181, ('MT', 'MTR'): 182, ('KZ', 'ZD'): 183, ('LW', 'LWC'): 184, ('LW', 'MG'): 185, ('APDO', 'TWL'): 186, ('HON', 'RSN'): 187, ('DLD', 'STZ'): 188, ('ST', 'STZ'): 189, ('EML', 'PT'): 190, ('NKK', 'PT'): 191, ('APG', 'DZW'): 192, ('APG', 'LP'): 193, ('KBK', 'VEM'): 194, ('VEM', 'ZP'): 195, ('HNO', 'ZL'): 196, ('DV', 'ZP'): 197, ('UTLR', 'UTT'): 198, ('DVNK', 'VST'): 199, ('EDC', 'LTN'): 200, ('DN', 'HMBH'): 201, ('DN', 'HRT'): 202, ('HLM', 'HAD'): 203, ('HAD', 'HIL'): 204, ('HNP', 'KMW'): 205, ('DDR', 'DDZD'): 206, ('DDZD', 'ZLW'): 207, ('DID', 'WL'): 208, ('DTCH', 'WL'): 209, ('DID', 'ZV'): 210, ('BMR', 'VLB'): 211, ('VRY', 'VLB'): 212, ('RM', 'SM'): 213, ('RM', 'WT'): 214, ('AHPR', 'VP'): 215, ('RH', 'VP'): 216, ('BRD', 'ZWD'): 217, ('DDR', 'ZWD'): 218, ('HT', 'ZBM'): 219, ('AKM', 'GW'): 220, ('ASD', 'ASS'): 221, ('GVC', 'GV'): 222, ('APDM', 'KBK'): 223, ('HIL', 'VH'): 224, ('BDM', 'STM'): 225, ('LP', 'STM'): 226, ('GERP', 'HRN'): 227, ('ASA', 'DVD'): 228, ('AHPR', 'AHP'): 229, ('GERP', 'KW'): 230, ('KW', 'MTH'): 231, ('DMNZ', 'DVD'): 232, ('LEDN', 'LDL'): 233, ('LEDN', 'VH'): 234, ('IJT', 'SK'): 235, ('GO', 'LC'): 236, ('VTN', 'WD'): 237, ('GS', 'BZL'): 238, ('APD', 'APDM'): 239, ('BD', 'GZ'): 240, ('GZ', 'TBR'): 241, ('ATN', 'WW'): 242, ('AMF', 'BRN'): 243, ('HM', 'HMH'): 244, ('HMH', 'HMBV'): 245, ('ALMB', 'ALMO'): 246, ('ALMB', 'ALMP'): 247, ('AHP', 'WTV'): 248, ('BSKS', 'WADN'): 249, ('WAD', 'WADN'): 250, ('EC', 'RM'): 251, ('AML', 'AMRI'): 252, ('AMR', 'AMRN'): 253, ('DRON', 'KPNZ'): 254, ('HGL', 'HGLO'): 255, ('GV', 'GVMW'): 256, ('HNO', 'RAT'): 257, ('AMF', 'AMFS'): 258, ('AMFS', 'AVAT'): 259, ('HFD', 'RTD'): 260, ('HFD', 'SHL'): 261, ('HRL', 'HB'): 262, ('UT', 'UTZL'): 263, ('DDR', 'DDRS'): 264, ('MG', 'SKND'): 265, ('SK', 'SKND'): 266, ('TL', 'TPSW'): 267, ('BSD', 'GDM'): 268, ('GLN', 'STD'): 269, ('LUT', 'STD'): 270, ('BD', 'BDPB'): 271, ('BD', 'ETN'): 272, ('WW', 'WWW'): 273, ('EML', 'HD'): 274, ('HD', 'NS'): 275, ('NVD', 'RAT'): 276, ('GW', 'LW'): 277, ('RL', 'VD'): 278, ('ASD', 'ASDM'): 279, ('ASDM', 'ASSP'): 280, ('HLMS', 'HWZB'): 281, ('ES', 'ESE'): 282, ('ES', 'ESK'): 283, ('DVN', 'WTV'): 284, ('DVN', 'ZV'): 285, ('BGN', 'RSD'): 286, ('AVAT', 'NKK'): 287, ('ASN', 'HRN'): 288, ('EMNZ', 'NA'): 289, ('BDE', 'MTN'): 290, ('BSMZ', 'NDB'): 291, ('HFD', 'NVP'): 292, ('NVP', 'SSH'): 293, ('ASDL', 'SHL'): 294, ('GVC', 'VB'): 295, ('HMN', 'OP'): 296, ('HMN', 'ZA'): 297, ('RTA', 'RTN'): 298, ('RTD', 'RTN'): 299, ('AMR', 'HLO'): 300, ('MRN', 'KLP'): 301, ('RTB', 'RTD'): 302, ('RTB', 'RTZ'): 303, ('APN', 'LDL'): 304, ('ASN', 'BL'): 305, ('BL', 'HGV'): 306, ('AC', 'BKL'): 307, ('BKL', 'WD'): 308, ('UTLN', 'UTVR'): 309, ('SDA', 'WS'): 310, ('DV', 'DVC'): 311, ('MMLH', 'NMH'): 312, ('NM', 'NMH'): 313, ('DRP', 'FN'): 314, ('ODB', 'RSD'): 315, ('DEI', 'DRP'): 316, ('HRL', 'HRLW'): 317, ('AML', 'VZ'): 318, ('DA', 'VZ'): 319, ('BMN', 'DR'): 320, ('DR', 'RH'): 321, ('GLN', 'SBK'): 322, ('SN', 'SBK'): 323, ('TB', 'TBU'): 324, ('BNC', 'BNN'): 325, ('DEI', 'LW'): 326, ('SGL', 'VK'): 327, ('SOG', 'VK'): 328, ('CPS', 'RTA'): 329, ('BDM', 'SWD'): 330, ('ASA', 'ASDM'): 331, ('RTD', 'SDM'): 332, ('NVD', 'WDN'): 333, ('GD', 'LLZM'): 334, ('MRB', 'OMN'): 335, ('BKG', 'HKS'): 336, ('HKS', 'HNK'): 337, ('DMN', 'DMNZ'): 338, ('UTT', 'VTN'): 339, ('DRON', 'LLS'): 340, ('APN', 'BSK'): 341, ('BSK', 'BSKS'): 342, ('RV', 'TG'): 343, ('TG', 'VL'): 344, ('AMF', 'HVL'): 345, ('DT', 'RSW'): 346, ('BSD', 'LDM'): 347, ('ASDZ', 'SHL'): 348, ('HLM', 'OVN'): 349, ('KMR', 'SOG'): 350, ('KMR', 'VDL'): 351, ('ALMO', 'LLS'): 352, ('HVS', 'HVSP'): 353, ('GD', 'WADT'): 354, ('ANA', 'SGN'): 355, ('HWD', 'SGN'): 356, ('YPB', 'VB'): 357, ('YPB', 'ZTM'): 358, ('GK', 'ZH'): 359, ('AMRI', 'BN'): 360, ('KZ', 'ZZS'): 361, ('BRD', 'RLB'): 362, ('RLB', 'RTST'): 363, ('APN', 'BDG'): 364, ('EST', 'NML'): 365, ('NM', 'NML'): 366, ('ANA', 'HDRZ'): 367, ('RTST', 'RTZ'): 368, ('RD', 'UHM'): 369, ('ODB', 'ZVB'): 370, ('BZL', 'KRG'): 371, ('CAS', 'HLO'): 372, ('DL', 'OMN'): 373, ('LAA', 'GVM'): 374, ('HDE', 'WZ'): 375, ('ZTM', 'ZTMO'): 376, ('GBG', 'HDB'): 377, ('MT', 'MTN'): 378, ('MAS', 'UTZL'): 379, ('LTV', 'RL'): 380, ('ASSP', 'DMN'): 381, ('BKL', 'MAS'): 382, ('HDG', 'LWC'): 383, ('DRH', 'SPTN'): 384, ('SPTN', 'SPTZ'): 385, ('WAD', 'WADT'): 386, ('HZE', 'MZ'): 387, ('MZ', 'WT'): 388, ('BV', 'DRH'): 389, ('BV', 'HK'): 390, ('SDA', 'ZB'): 391, ('EC', 'SRN'): 392, ('LLZM', 'ZTMO'): 393, ('BR', 'VL'): 394, ('DTC', 'DTCH'): 395, ('DTC', 'GDR'): 396, ('O', 'OW'): 397, ('O', 'RVS'): 398, ('SDT', 'SDTB'): 399, ('ETN', 'RSD'): 400, ('LTV', 'WWW'): 401, ('CL', 'HTNC'): 402, ('HDE', 'NS'): 403, ('DDN', 'HGLG'): 404, ('HTN', 'HTNC'): 405, ('DDRS', 'SDTB'): 406, ('ALM', 'ALMM'): 407, ('ALM', 'ALMP'): 408, ('EST', 'ZA'): 409, ('AMPO', 'WP'): 410, ('TBR', 'TBU'): 411, ('DVC', 'HON'): 412, ('UHZ', 'UHM'): 413, ('UHZ', 'UST'): 414, ('HRLW', 'VDL'): 415, ('HTN', 'UTLN'): 416, ('GVM', 'VST'): 417, ('HM', 'HMBH'): 418, ('STD', 'SRN'): 419, ('BK', 'BDE'): 420, ('GDR', 'TBG'): 421, ('ALMM', 'AMPO'): 422, ('UST', 'WFM'): 423, ('DDN', 'GO'): 424, ('GVMW', 'RSW'): 425, ('NM', 'NMGO'): 426, ('BK', 'LUT'): 427, ('RAI', 'ASDZ'): 428, ('RV', 'SM'): 429, ('BF', 'WFM'): 430}\n",
      "{0: ('NSCH', 'WS'), 1: ('DZ', 'DZW'), 2: ('HDR', 'HDRZ'), 3: ('EEM', 'RD'), 4: ('EDN', 'MTR'), 5: ('EMN', 'EMNZ'), 6: ('BKF', 'EKZ'), 7: ('EGHM', 'LG'), 8: ('ESE', 'GBR'), 9: ('HLG', 'HLGH'), 10: ('KPN', 'ZLSH'), 11: ('CVM', 'KRD'), 12: ('HGLO', 'ODZ'), 13: ('RHN', 'VNDC'), 14: ('KMW', 'STV'), 15: ('UTM', 'UTO'), 16: ('VDM', 'ZB'), 17: ('VS', 'VSS'), 18: ('OVN', 'ZVT'), 19: ('ATN', 'VSV'), 20: ('TBG', 'VSV'), 21: ('BGN', 'RB'), 22: ('KBD', 'RB'), 23: ('DL', 'ZL'), 24: ('WH', 'ZL'), 25: ('GN', 'GNN'), 26: ('GNN', 'SWD'), 27: ('AC', 'ASHD'), 28: ('ASB', 'ASHD'), 29: ('HGZ', 'MTH'), 30: ('HGZ', 'ZB'), 31: ('HVSP', 'HOR'), 32: ('HOR', 'UTO'), 33: ('BTL', 'OT'), 34: ('BTL', 'VG'), 35: ('BLL', 'HLM'), 36: ('HLM', 'HLMS'), 37: ('DT', 'DTCP'), 38: ('DTCP', 'SDM'), 39: ('PMR', 'PMW'), 40: ('PMW', 'ZDK'), 41: ('HNP', 'WK'), 42: ('IJT', 'WK'), 43: ('BHV', 'UTO'), 44: ('UT', 'UTO'), 45: ('BMR', 'CK'), 46: ('CK', 'MMLH'), 47: ('HT', 'HTO'), 48: ('HT', 'TB'), 49: ('BSMZ', 'HVSM'), 50: ('HVS', 'HVSM'), 51: ('BKF', 'BKG'), 52: ('AKL', 'GR'), 53: ('AKL', 'LDM'), 54: ('AKM', 'HR'), 55: ('HR', 'HRY'), 56: ('ZL', 'ZLSH'), 57: ('BP', 'DWE'), 58: ('BP', 'GK'), 59: ('CO', 'DLN'), 60: ('DLN', 'NA'), 61: ('APD', 'APDO'), 62: ('APD', 'BNN'), 63: ('HT', 'VG'), 64: ('CO', 'GBG'), 65: ('ARN', 'MDB'), 66: ('MDB', 'VS'), 67: ('OST', 'WH'), 68: ('DVNK', 'LEDN'), 69: ('LEDN', 'SSH'), 70: ('BLL', 'SPTZ'), 71: ('EHV', 'EHS'), 72: ('EHV', 'HMBV'), 73: ('ASB', 'DVD'), 74: ('RAI', 'DVD'), 75: ('BET', 'BTL'), 76: ('BET', 'EHS'), 77: ('BRN', 'HVS'), 78: ('OT', 'TB'), 79: ('BNK', 'DB'), 80: ('DB', 'MRN'), 81: ('GDM', 'TPSW'), 82: ('GDM', 'ZBM'), 83: ('GD', 'GDG'), 84: ('GDG', 'WD'), 85: ('DMN', 'WP'), 86: ('NDB', 'WP'), 87: ('KPNZ', 'ZL'), 88: ('HB', 'NH'), 89: ('NH', 'SN'), 90: ('AH', 'AHZ'), 91: ('AH', 'OTB'), 92: ('BRD', 'ZLW'), 93: ('BDPB', 'ZLW'), 94: ('KMA', 'WM'), 95: ('WM', 'ZZS'), 96: ('HDB', 'MRB'), 97: ('MRB', 'VHP'), 98: ('ARN', 'GS'), 99: ('HBZM', 'GND'), 100: ('HBZM', 'SDT'), 101: ('BF', 'WSM'), 102: ('SWD', 'WSM'), 103: ('AMRN', 'HWD'), 104: ('HWD', 'OBD'), 105: ('DV', 'OST'), 106: ('ZLW', 'ZVB'), 107: ('CVM', 'EGH'), 108: ('EGH', 'LG'), 109: ('BNC', 'BNZ'), 110: ('BNZ', 'LTN'), 111: ('SGL', 'MES'), 112: ('MTN', 'MES'), 113: ('CPS', 'NWK'), 114: ('GD', 'NWK'), 115: ('BRN', 'SD'), 116: ('ST', 'SD'), 117: ('WZ', 'ZL'), 118: ('ASS', 'HWZB'), 119: ('ASS', 'ZD'), 120: ('KBD', 'KRG'), 121: ('BR', 'HRT'), 122: ('BR', 'VRY'), 123: ('HRY', 'WV'), 124: ('SWK', 'WV'), 125: ('HTO', 'RS'), 126: ('OW', 'RS'), 127: ('ED', 'WF'), 128: ('OTB', 'WF'), 129: ('HGV', 'MP'), 130: ('MP', 'SWK'), 131: ('AML', 'WDN'), 132: ('RSN', 'WDN'), 133: ('HRL', 'LG'), 134: ('ED', 'KLP'), 135: ('NMD', 'WC'), 136: ('RVS', 'WC'), 137: ('AH', 'AHP'), 138: ('BMN', 'ZP'), 139: ('LC', 'ZP'), 140: ('EDC', 'ED'), 141: ('DWE', 'FWD'), 142: ('FWD', 'HDG'), 143: ('BHDV', 'GR'), 144: ('BHDV', 'GND'), 145: ('BNN', 'HVL'), 146: ('BDG', 'WD'), 147: ('MRN', 'VNDW'), 148: ('VNDC', 'VNDW'), 149: ('ESK', 'HGL'), 150: ('HGL', 'HGLG'), 151: ('HN', 'OBD'), 152: ('CL', 'GDM'), 153: ('UT', 'UTLR'), 154: ('UT', 'UTVR'), 155: ('GVC', 'LAA'), 156: ('GV', 'LAA'), 157: ('DV', 'TWL'), 158: ('MP', 'ZL'), 159: ('HK', 'UTG'), 160: ('KMA', 'UTG'), 161: ('HN', 'HNK'), 162: ('HN', 'PMO'), 163: ('ASDL', 'ASS'), 164: ('NMD', 'NMGO'), 165: ('BN', 'HGL'), 166: ('ZD', 'ZDK'), 167: ('KTR', 'OP'), 168: ('KTR', 'TL'), 169: ('CAS', 'UTG'), 170: ('VD', 'ZP'), 171: ('FN', 'HLG'), 172: ('DA', 'VHP'), 173: ('BNK', 'UTVR'), 174: ('PMR', 'PMO'), 175: ('EHV', 'GP'), 176: ('GP', 'HZE'), 177: ('GN', 'GERP'), 178: ('GN', 'ZH'), 179: ('AMF', 'DLD'), 180: ('BHV', 'DLD'), 181: ('AHZ', 'EST'), 182: ('MT', 'MTR'), 183: ('KZ', 'ZD'), 184: ('LW', 'LWC'), 185: ('LW', 'MG'), 186: ('APDO', 'TWL'), 187: ('HON', 'RSN'), 188: ('DLD', 'STZ'), 189: ('ST', 'STZ'), 190: ('EML', 'PT'), 191: ('NKK', 'PT'), 192: ('APG', 'DZW'), 193: ('APG', 'LP'), 194: ('KBK', 'VEM'), 195: ('VEM', 'ZP'), 196: ('HNO', 'ZL'), 197: ('DV', 'ZP'), 198: ('UTLR', 'UTT'), 199: ('DVNK', 'VST'), 200: ('EDC', 'LTN'), 201: ('DN', 'HMBH'), 202: ('DN', 'HRT'), 203: ('HLM', 'HAD'), 204: ('HAD', 'HIL'), 205: ('HNP', 'KMW'), 206: ('DDR', 'DDZD'), 207: ('DDZD', 'ZLW'), 208: ('DID', 'WL'), 209: ('DTCH', 'WL'), 210: ('DID', 'ZV'), 211: ('BMR', 'VLB'), 212: ('VRY', 'VLB'), 213: ('RM', 'SM'), 214: ('RM', 'WT'), 215: ('AHPR', 'VP'), 216: ('RH', 'VP'), 217: ('BRD', 'ZWD'), 218: ('DDR', 'ZWD'), 219: ('HT', 'ZBM'), 220: ('AKM', 'GW'), 221: ('ASD', 'ASS'), 222: ('GVC', 'GV'), 223: ('APDM', 'KBK'), 224: ('HIL', 'VH'), 225: ('BDM', 'STM'), 226: ('LP', 'STM'), 227: ('GERP', 'HRN'), 228: ('ASA', 'DVD'), 229: ('AHPR', 'AHP'), 230: ('GERP', 'KW'), 231: ('KW', 'MTH'), 232: ('DMNZ', 'DVD'), 233: ('LEDN', 'LDL'), 234: ('LEDN', 'VH'), 235: ('IJT', 'SK'), 236: ('GO', 'LC'), 237: ('VTN', 'WD'), 238: ('GS', 'BZL'), 239: ('APD', 'APDM'), 240: ('BD', 'GZ'), 241: ('GZ', 'TBR'), 242: ('ATN', 'WW'), 243: ('AMF', 'BRN'), 244: ('HM', 'HMH'), 245: ('HMH', 'HMBV'), 246: ('ALMB', 'ALMO'), 247: ('ALMB', 'ALMP'), 248: ('AHP', 'WTV'), 249: ('BSKS', 'WADN'), 250: ('WAD', 'WADN'), 251: ('EC', 'RM'), 252: ('AML', 'AMRI'), 253: ('AMR', 'AMRN'), 254: ('DRON', 'KPNZ'), 255: ('HGL', 'HGLO'), 256: ('GV', 'GVMW'), 257: ('HNO', 'RAT'), 258: ('AMF', 'AMFS'), 259: ('AMFS', 'AVAT'), 260: ('HFD', 'RTD'), 261: ('HFD', 'SHL'), 262: ('HRL', 'HB'), 263: ('UT', 'UTZL'), 264: ('DDR', 'DDRS'), 265: ('MG', 'SKND'), 266: ('SK', 'SKND'), 267: ('TL', 'TPSW'), 268: ('BSD', 'GDM'), 269: ('GLN', 'STD'), 270: ('LUT', 'STD'), 271: ('BD', 'BDPB'), 272: ('BD', 'ETN'), 273: ('WW', 'WWW'), 274: ('EML', 'HD'), 275: ('HD', 'NS'), 276: ('NVD', 'RAT'), 277: ('GW', 'LW'), 278: ('RL', 'VD'), 279: ('ASD', 'ASDM'), 280: ('ASDM', 'ASSP'), 281: ('HLMS', 'HWZB'), 282: ('ES', 'ESE'), 283: ('ES', 'ESK'), 284: ('DVN', 'WTV'), 285: ('DVN', 'ZV'), 286: ('BGN', 'RSD'), 287: ('AVAT', 'NKK'), 288: ('ASN', 'HRN'), 289: ('EMNZ', 'NA'), 290: ('BDE', 'MTN'), 291: ('BSMZ', 'NDB'), 292: ('HFD', 'NVP'), 293: ('NVP', 'SSH'), 294: ('ASDL', 'SHL'), 295: ('GVC', 'VB'), 296: ('HMN', 'OP'), 297: ('HMN', 'ZA'), 298: ('RTA', 'RTN'), 299: ('RTD', 'RTN'), 300: ('AMR', 'HLO'), 301: ('MRN', 'KLP'), 302: ('RTB', 'RTD'), 303: ('RTB', 'RTZ'), 304: ('APN', 'LDL'), 305: ('ASN', 'BL'), 306: ('BL', 'HGV'), 307: ('AC', 'BKL'), 308: ('BKL', 'WD'), 309: ('UTLN', 'UTVR'), 310: ('SDA', 'WS'), 311: ('DV', 'DVC'), 312: ('MMLH', 'NMH'), 313: ('NM', 'NMH'), 314: ('DRP', 'FN'), 315: ('ODB', 'RSD'), 316: ('DEI', 'DRP'), 317: ('HRL', 'HRLW'), 318: ('AML', 'VZ'), 319: ('DA', 'VZ'), 320: ('BMN', 'DR'), 321: ('DR', 'RH'), 322: ('GLN', 'SBK'), 323: ('SN', 'SBK'), 324: ('TB', 'TBU'), 325: ('BNC', 'BNN'), 326: ('DEI', 'LW'), 327: ('SGL', 'VK'), 328: ('SOG', 'VK'), 329: ('CPS', 'RTA'), 330: ('BDM', 'SWD'), 331: ('ASA', 'ASDM'), 332: ('RTD', 'SDM'), 333: ('NVD', 'WDN'), 334: ('GD', 'LLZM'), 335: ('MRB', 'OMN'), 336: ('BKG', 'HKS'), 337: ('HKS', 'HNK'), 338: ('DMN', 'DMNZ'), 339: ('UTT', 'VTN'), 340: ('DRON', 'LLS'), 341: ('APN', 'BSK'), 342: ('BSK', 'BSKS'), 343: ('RV', 'TG'), 344: ('TG', 'VL'), 345: ('AMF', 'HVL'), 346: ('DT', 'RSW'), 347: ('BSD', 'LDM'), 348: ('ASDZ', 'SHL'), 349: ('HLM', 'OVN'), 350: ('KMR', 'SOG'), 351: ('KMR', 'VDL'), 352: ('ALMO', 'LLS'), 353: ('HVS', 'HVSP'), 354: ('GD', 'WADT'), 355: ('ANA', 'SGN'), 356: ('HWD', 'SGN'), 357: ('YPB', 'VB'), 358: ('YPB', 'ZTM'), 359: ('GK', 'ZH'), 360: ('AMRI', 'BN'), 361: ('KZ', 'ZZS'), 362: ('BRD', 'RLB'), 363: ('RLB', 'RTST'), 364: ('APN', 'BDG'), 365: ('EST', 'NML'), 366: ('NM', 'NML'), 367: ('ANA', 'HDRZ'), 368: ('RTST', 'RTZ'), 369: ('RD', 'UHM'), 370: ('ODB', 'ZVB'), 371: ('BZL', 'KRG'), 372: ('CAS', 'HLO'), 373: ('DL', 'OMN'), 374: ('LAA', 'GVM'), 375: ('HDE', 'WZ'), 376: ('ZTM', 'ZTMO'), 377: ('GBG', 'HDB'), 378: ('MT', 'MTN'), 379: ('MAS', 'UTZL'), 380: ('LTV', 'RL'), 381: ('ASSP', 'DMN'), 382: ('BKL', 'MAS'), 383: ('HDG', 'LWC'), 384: ('DRH', 'SPTN'), 385: ('SPTN', 'SPTZ'), 386: ('WAD', 'WADT'), 387: ('HZE', 'MZ'), 388: ('MZ', 'WT'), 389: ('BV', 'DRH'), 390: ('BV', 'HK'), 391: ('SDA', 'ZB'), 392: ('EC', 'SRN'), 393: ('LLZM', 'ZTMO'), 394: ('BR', 'VL'), 395: ('DTC', 'DTCH'), 396: ('DTC', 'GDR'), 397: ('O', 'OW'), 398: ('O', 'RVS'), 399: ('SDT', 'SDTB'), 400: ('ETN', 'RSD'), 401: ('LTV', 'WWW'), 402: ('CL', 'HTNC'), 403: ('HDE', 'NS'), 404: ('DDN', 'HGLG'), 405: ('HTN', 'HTNC'), 406: ('DDRS', 'SDTB'), 407: ('ALM', 'ALMM'), 408: ('ALM', 'ALMP'), 409: ('EST', 'ZA'), 410: ('AMPO', 'WP'), 411: ('TBR', 'TBU'), 412: ('DVC', 'HON'), 413: ('UHZ', 'UHM'), 414: ('UHZ', 'UST'), 415: ('HRLW', 'VDL'), 416: ('HTN', 'UTLN'), 417: ('GVM', 'VST'), 418: ('HM', 'HMBH'), 419: ('STD', 'SRN'), 420: ('BK', 'BDE'), 421: ('GDR', 'TBG'), 422: ('ALMM', 'AMPO'), 423: ('UST', 'WFM'), 424: ('DDN', 'GO'), 425: ('GVMW', 'RSW'), 426: ('NM', 'NMGO'), 427: ('BK', 'LUT'), 428: ('RAI', 'ASDZ'), 429: ('RV', 'SM'), 430: ('BF', 'WFM')}\n"
     ]
    }
   ],
   "source": [
    "node2idx = {n:i for i,n in enumerate(LG.nodes())}\n",
    "idx2node = {i:n for i,n in enumerate(LG.nodes())}\n",
    "print(node2idx)\n",
    "print(idx2node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1eafd139",
   "metadata": {},
   "outputs": [],
   "source": [
    "incident_edges = {n: [] for n in LG.nodes()}\n",
    "for u, v in LG.edges():\n",
    "    incident_edges[u].append((u, v))\n",
    "    incident_edges[v].append((u, v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c399dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linegraph_to_pyg(LG, default_edge_weight = 1.0):\n",
    "    X = []\n",
    "    Y = []\n",
    "    for node in node2idx:\n",
    "        feature_vector = []\n",
    "        for feat in WEATHER_FEATURES:\n",
    "            mean_value = 0\n",
    "            for (u, v) in incident_edges[node]:\n",
    "                mean_value = mean_value + LG.edges[(u,v)][feat]\n",
    "            mean_value = mean_value / len(incident_edges[node])\n",
    "            feature_vector.append(mean_value)\n",
    "        X.append(feature_vector)\n",
    "        Y.append(LG.nodes[node][\"duration\"])\n",
    "    X = torch.tensor(X, dtype=torch.float32)\n",
    "    Y = torch.tensor(Y, dtype=torch.float32)\n",
    "\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53c7bab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dae0f2ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([744, 431, 9])\n",
      "torch.Size([744, 431])\n"
     ]
    }
   ],
   "source": [
    "X_seq = []\n",
    "Y_seq = []\n",
    "edge_index = []\n",
    "edge_weights = []\n",
    "\n",
    "for t in SNAPSHOTS:\n",
    "    graph = SNAPSHOTS[t]\n",
    "    G = build_minimal_graph(graph)\n",
    "    LG = make_linegraph(G)\n",
    "    X, Y = linegraph_to_pyg(LG)\n",
    "    X_seq.append(X)\n",
    "    Y_seq.append(Y)\n",
    "X_seq = torch.stack(X_seq)\n",
    "Y_seq = torch.stack(Y_seq)\n",
    "print(X_seq.shape)\n",
    "print(Y_seq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd4ff869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1162])\n",
      "torch.Size([1162])\n"
     ]
    }
   ],
   "source": [
    "default_edge_weight = 1\n",
    "idx_pairs = []\n",
    "edge_weights = []\n",
    "for (u, v) in LG.edges():\n",
    "    idx_pairs.append((node2idx[u], node2idx[v]))\n",
    "    edge_weights.append(default_edge_weight)\n",
    "    idx_pairs.append((node2idx[v], node2idx[u]))\n",
    "    edge_weights.append(default_edge_weight)\n",
    "edge_index = torch.tensor(idx_pairs, dtype=torch.long).t().contiguous()\n",
    "edge_weights = torch.full((edge_index.size(1),), 1.0, dtype=torch.float32)\n",
    "edge_index = edge_index.to(dtype=torch.long, device=device)\n",
    "edge_weights = edge_weights.to(dtype=torch.float32, device=device)\n",
    "print(edge_index.shape)\n",
    "print(edge_weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0412de22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(X_seq, Y_seq, train_ratio=0.6, val_ratio=0.2):\n",
    "    total = len(X_seq)\n",
    "    n_train = math.floor(total * train_ratio)\n",
    "    n_val   = math.floor(total * val_ratio)\n",
    "\n",
    "    X_train = X_seq[:n_train]\n",
    "    Y_train = Y_seq[:n_train]\n",
    "\n",
    "    X_val   = X_seq[n_train:n_train+n_val]\n",
    "    Y_val   = Y_seq[n_train:n_train+n_val]\n",
    "\n",
    "    X_test  = X_seq[n_train+n_val:]\n",
    "    Y_test  = Y_seq[n_train+n_val:]\n",
    "\n",
    "\n",
    "    return X_train, Y_train, X_val, Y_val, X_test, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "94d9904f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def slide_window(X_seq, Y_seq, window_sizes):\n",
    "    T, N, F = X_seq.shape\n",
    "\n",
    "    X_list = []\n",
    "    Y_list = []\n",
    "    for W in window_sizes:\n",
    "        for t in range(W, T):\n",
    "            X_window = X_seq[t-W:t]\n",
    "            Y_next = Y_seq[t]\n",
    "            X_list.append(X_window)\n",
    "            Y_list.append(Y_next)\n",
    "\n",
    "    return X_list, Y_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71ff4c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([446, 431, 9])\n",
      "torch.Size([446, 431])\n",
      "torch.Size([148, 431, 9])\n",
      "torch.Size([148, 431])\n",
      "torch.Size([150, 431, 9])\n",
      "torch.Size([150, 431])\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train, X_val, Y_val, X_test, Y_test = split_dataset(X_seq, Y_seq)\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_val.shape)\n",
    "print(Y_val.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e73daedd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2144\n",
      "2144\n",
      "654\n",
      "654\n",
      "664\n",
      "664\n"
     ]
    }
   ],
   "source": [
    "window_sizes = [48, 24, 8, 4, 2]\n",
    "X_train_window, Y_train_window = slide_window(X_train, Y_train, window_sizes)\n",
    "X_val_window, Y_val_window = slide_window(X_val, Y_val, window_sizes)\n",
    "X_test_window, Y_test_window = slide_window(X_test, Y_test, window_sizes)\n",
    "print(len(X_train_window))\n",
    "print(len(Y_train_window))\n",
    "print(len(X_val_window))\n",
    "print(len(Y_val_window))\n",
    "print(len(X_test_window))\n",
    "print(len(Y_test_window))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90380a77",
   "metadata": {},
   "source": [
    "- Very simple GCN encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "283ae2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNEncoder(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight):\n",
    "        x = self.conv1(x, edge_index, edge_weight)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index, edge_weight)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eabb161",
   "metadata": {},
   "source": [
    "- GCN + RNN Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c7a3dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN_RNN(nn.Module):\n",
    "    def __init__(self, in_channels, gcn_hidden, rnn_hidden=64):\n",
    "        super().__init__()\n",
    "        self.gcn = GCNEncoder(in_channels, gcn_hidden)\n",
    "        self.gru = nn.GRU(input_size=gcn_hidden, hidden_size=rnn_hidden, num_layers=1)\n",
    "        self.out = nn.Linear(rnn_hidden, 1)\n",
    "\n",
    "    def forward(self, X_seq, edge_index, edge_weight):\n",
    "        # for all graphs_0 ... graph_t\n",
    "        H_t = []\n",
    "        for x in X_seq:\n",
    "            # get the embeddings at t\n",
    "            h = self.gcn(x, edge_index, edge_weight)\n",
    "            # stack all the embeddings \n",
    "            H_t.append(h)\n",
    "        H = torch.stack(H_t, dim=0)\n",
    "        \n",
    "        # RNN on embedding sequence\n",
    "        H_gru, _ = self.gru(H)\n",
    "        # summarized state i.e the last state\n",
    "        last = H_gru[-1]\n",
    "        # from embeddings to prediction\n",
    "        y = self.out(last)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f8ce6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, optim, X_windows, Y_windows):\n",
    "    model.train()\n",
    "\n",
    "    for X_seq, Y_true in zip(X_windows, Y_windows):\n",
    "\n",
    "        X_seq = X_seq.to(torch.float32).to(device)\n",
    "        Y_true = Y_true.to(torch.float32).to(device)\n",
    "\n",
    "        y_pred = model(X_seq, edge_index, edge_weights)\n",
    "\n",
    "        loss = F.mse_loss(y_pred, Y_true.unsqueeze(-1))\n",
    "\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f3a71edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, X_windows, Y_windows):\n",
    "    model.eval()\n",
    "    eval_loss = 0.0\n",
    "\n",
    "    for X_seq, Y_true in zip(X_windows, Y_windows):\n",
    "        X_seq = X_seq.to(torch.float32).to(device)\n",
    "        Y_true = Y_true.to(torch.float32).to(device)\n",
    "\n",
    "        y_pred = model(X_seq, edge_index, edge_weights)  # [N,1]\n",
    "        loss = F.mse_loss(y_pred, Y_true.unsqueeze(-1))\n",
    "        eval_loss += loss.item()\n",
    "\n",
    "    avg_loss = eval_loss / len(X_windows)\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f68c6cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training_for_config(in_channels, gcn_hidden, rnn_hidden, lr, num_epochs,):\n",
    "    model = GCN_RNN(in_channels, gcn_hidden, rnn_hidden).to(device)\n",
    "\n",
    "    optim = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    best_val = float(\"inf\")\n",
    "    best_state = None\n",
    "    best_epochs = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_one_epoch(model, optim, X_train_window, Y_train_window,)\n",
    "        val_loss = evaluate(model, X_val_window, Y_val_window)\n",
    "\n",
    "        # keep best\n",
    "        if val_loss < best_val:\n",
    "            best_val = val_loss\n",
    "            best_epochs = epoch\n",
    "\n",
    "    test_loss = evaluate(model, X_test_window, Y_test_window)\n",
    "\n",
    "    return {\n",
    "        \"best_epoch\": best_epochs,\n",
    "        \"best_val_loss\": best_val,\n",
    "        \"test_loss\": test_loss,\n",
    "        \"gcn_hidden\": gcn_hidden,\n",
    "        \"rnn_hidden\": rnn_hidden,\n",
    "        \"lr\": lr,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ed3090",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     16\u001b[39m results = []\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m gcn_h, rnn_h, lr \u001b[38;5;129;01min\u001b[39;00m configs:\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m     out = \u001b[43mrun_training_for_config\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mWEATHER_FEATURES\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgcn_hidden\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgcn_h\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrnn_hidden\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrnn_h\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m     results.append(out)\n\u001b[32m     22\u001b[39m     \u001b[38;5;28mprint\u001b[39m(gcn_h, rnn_h, lr, \u001b[33m\"\u001b[39m\u001b[33mFinished\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 11\u001b[39m, in \u001b[36mrun_training_for_config\u001b[39m\u001b[34m(in_channels, gcn_hidden, rnn_hidden, lr, num_epochs)\u001b[39m\n\u001b[32m      8\u001b[39m best_epochs = \u001b[32m0\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m     \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_window\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train_window\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m     val_loss = evaluate(model, X_val_window, Y_val_window)\n\u001b[32m     14\u001b[39m     \u001b[38;5;66;03m# keep best\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mtrain_one_epoch\u001b[39m\u001b[34m(model, optim, X_windows, Y_windows)\u001b[39m\n\u001b[32m      6\u001b[39m X_seq = X_seq.to(torch.float32).to(device)\n\u001b[32m      7\u001b[39m Y_true = Y_true.to(torch.float32).to(device)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m y_pred = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_seq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m loss = F.mse_loss(y_pred, Y_true.unsqueeze(-\u001b[32m1\u001b[39m))\n\u001b[32m     13\u001b[39m optim.zero_grad()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\andre\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\andre\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 13\u001b[39m, in \u001b[36mGCN_RNN.forward\u001b[39m\u001b[34m(self, X_seq, edge_index, edge_weight)\u001b[39m\n\u001b[32m     10\u001b[39m H_t = []\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m X_seq:\n\u001b[32m     12\u001b[39m     \u001b[38;5;66;03m# get the embeddings at t\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m     h = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgcn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m     \u001b[38;5;66;03m# stack all the embeddings \u001b[39;00m\n\u001b[32m     15\u001b[39m     H_t.append(h)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\andre\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\andre\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36mGCNEncoder.forward\u001b[39m\u001b[34m(self, x, edge_index, edge_weight)\u001b[39m\n\u001b[32m      8\u001b[39m x = \u001b[38;5;28mself\u001b[39m.conv1(x, edge_index, edge_weight)\n\u001b[32m      9\u001b[39m x = F.relu(x)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconv2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\andre\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\andre\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\andre\\miniconda3\\Lib\\site-packages\\torch_geometric\\nn\\conv\\gcn_conv.py:241\u001b[39m, in \u001b[36mGCNConv.forward\u001b[39m\u001b[34m(self, x, edge_index, edge_weight)\u001b[39m\n\u001b[32m    239\u001b[39m cache = \u001b[38;5;28mself\u001b[39m._cached_edge_index\n\u001b[32m    240\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m241\u001b[39m     edge_index, edge_weight = \u001b[43mgcn_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# yapf: disable\u001b[39;49;00m\n\u001b[32m    242\u001b[39m \u001b[43m        \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnode_dim\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    243\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mimproved\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madd_self_loops\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mflow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    244\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cached:\n\u001b[32m    245\u001b[39m         \u001b[38;5;28mself\u001b[39m._cached_edge_index = (edge_index, edge_weight)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\andre\\miniconda3\\Lib\\site-packages\\torch_geometric\\nn\\conv\\gcn_conv.py:99\u001b[39m, in \u001b[36mgcn_norm\u001b[39m\u001b[34m(edge_index, edge_weight, num_nodes, improved, add_self_loops, flow, dtype)\u001b[39m\n\u001b[32m     96\u001b[39m num_nodes = maybe_num_nodes(edge_index, num_nodes)\n\u001b[32m     98\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m add_self_loops:\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m     edge_index, edge_weight = \u001b[43madd_remaining_self_loops\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    100\u001b[39m \u001b[43m        \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_nodes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m edge_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    103\u001b[39m     edge_weight = torch.ones((edge_index.size(\u001b[32m1\u001b[39m), ), dtype=dtype,\n\u001b[32m    104\u001b[39m                              device=edge_index.device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\andre\\miniconda3\\Lib\\site-packages\\torch_geometric\\utils\\loop.py:655\u001b[39m, in \u001b[36madd_remaining_self_loops\u001b[39m\u001b[34m(edge_index, edge_attr, fill_value, num_nodes)\u001b[39m\n\u001b[32m    652\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch.jit.is_scripting() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(edge_index, EdgeIndex):\n\u001b[32m    653\u001b[39m     edge_index._is_undirected = is_undirected\n\u001b[32m--> \u001b[39m\u001b[32m655\u001b[39m edge_index = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloop_index\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    657\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m edge_index, edge_attr\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "in_channels = len(WEATHER_FEATURES)\n",
    "\n",
    "configs = [\n",
    "    # (gcn_hidden, rnn_hidden, lr)\n",
    "    (32, 32, 1e-3),\n",
    "    (64, 64, 1e-3),\n",
    "    (128, 128, 1e-3),\n",
    "    (32, 32, 5e-3),\n",
    "    (64, 64, 5e-3),\n",
    "    (128, 128, 5e-3),\n",
    "    (32, 32, 1e-2),\n",
    "    (64, 64, 1e-2),\n",
    "    (128, 128, 1e-2),\n",
    "]\n",
    "\n",
    "results = []\n",
    "for gcn_h, rnn_h, lr in configs:\n",
    "    out = run_training_for_config(len(WEATHER_FEATURES), gcn_hidden=gcn_h, rnn_hidden=rnn_h, lr=lr, num_epochs=50)\n",
    "    results.append(out)\n",
    "    print(gcn_h, rnn_h, lr, \"Finished\")\n",
    "    print(out)\n",
    "\n",
    "results = sorted(results, key=lambda r: r[\"best_val_loss\"])\n",
    "\n",
    "fields = [\"gcn_hidden\", \"rnn_hidden\", \"lr\", \"best_val_loss\", \"test_loss\", \"best_epoch\"]\n",
    "\n",
    "csv_path = \"experiment_results.csv\"\n",
    "\n",
    "with open(csv_path, mode=\"w\", newline=\"\") as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=fields)\n",
    "    writer.writeheader()\n",
    "    for r in results:\n",
    "        row = {k: r[k] for k in fields}\n",
    "        writer.writerow(row)\n",
    "\n",
    "print(f\"Wrote {len(results)} rows to {csv_path}\")\n",
    "\n",
    "best = results[0]\n",
    "print(\"Best config:\", {k: best[k] for k in fields})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
